#Intergation tests for write_query_azure function

import sys
import os
import pytest

# Add the project root to the Python path instead of just the Code directory
sys.path.insert(0, os.path.abspath(os.path.join(os.path.dirname(__file__), '..')))

import sqlite3
from Code.azure_functions import write_query_azure, query_collection_azure, client
from langchain_community.utilities import SQLDatabase
import Code.config as cfg
from dotenv import load_dotenv

# Load environment variables
load_dotenv()

questions = [
        "How many actors are there in the database?", # 0
        "What is the name of the actor with ID 1?", # 1
        "List the first movies released in 2006.", # 2
        "Who directed the movie 'The Godfather'?", # 3
        "What is the average rental rate for movies?", # 4
        "How many customers are there in the database?", #5
        "What is the total revenue generated by all movies?", #6
        "Who are the top 5 actors with the most movies?", #7
        "List the first 5 movies released after 2010.", #8
        "What are the top 3 actors from the top 3 most rented movie categories?", #9
        "How the table 'actor' is related to the table 'film'?", #10
        "Qual a relação entre a tabela customer e a tabela rental?" #11
    ]

# Test questions and their corresponding expected queries (that we know produce correct results)
test_cases = [
    {
        "question": "How many actors are there in the database?",
        "expected_query": "SELECT COUNT(*) FROM actor;",
        "description": "Count total actors"
    },
    {
        "question": "What is the name of the actor with ID 1?", 
        "expected_query": "SELECT first_name, last_name FROM actor WHERE actor_id = 1;",
        "description": "Get specific actor by ID"
    },
    {
        "question": "List the first 3 movies released in 2006.",
        "expected_query": "SELECT title FROM film WHERE release_year = 2006 ORDER BY title LIMIT 3;",
        "description": "Get films by year with limit"
    },
    {
        "question": "What is the average rental rate for movies?",
        "expected_query": "SELECT AVG(rental_rate) FROM film;",
        "description": "Calculate average rental rate"
    },
    {
        "question": "How many customers are there in the database?",
        "expected_query": "SELECT COUNT(*) FROM customer;", 
        "description": "Count total customers"
    },
    {
        "question": "What is the total revenue generated by all rentals?",
        "expected_query": "SELECT SUM(amount) FROM payment;",
        "description": "Sum all payments"
    },
    {
        "question": "Who are the top 2 actors with the most movies?",
        "expected_query": "SELECT a.first_name, a.last_name, COUNT(fa.film_id) AS film_count FROM actor a JOIN film_actor fa ON a.actor_id = fa.actor_id GROUP BY a.actor_id, a.first_name, a.last_name ORDER BY film_count DESC LIMIT 2;",
        "description": "Top actors by film count"
    },
]


@pytest.fixture
def db_connection():
    """Create and return a database connection."""
    connection = sqlite3.connect(cfg.DB_PATH)
    yield connection
    connection.close()


class TestWriteQueryAzure:
    """Test cases for write_query_azure function by comparing query results."""
    
    def test_write_query_azure_results_comparison(self, db_connection):
        """Test write_query_azure by comparing results from generated vs expected queries."""
        
        cursor = db_connection.cursor()
        passed_tests = 0
        total_tests = len(test_cases)
        
        print(f"\n🧪 Running {total_tests} query generation tests...\n")
        
        for i, test_case in enumerate(test_cases):
            question = test_case["question"]
            expected_query = test_case["expected_query"]
            description = test_case["description"]
            
            print(f"🔍 Test {i+1}/{total_tests}: {description}")
            print(f"   Question: {question}")
            
            # Step 1: Execute expected query to get correct results
            try:
                cursor.execute(expected_query)
                expected_results = cursor.fetchall()
                print(f"   ✓ Expected query executed: {len(expected_results)} results")
                print(f"   📊 Expected query: {expected_query}")
            except Exception as e:
                print(f"   ❌ Error executing expected query: {e}")
                continue
            
            # Step 2: Get relevant tables from vector database
            try:
                tables = query_collection_azure(prompt=question)
                if not tables or not tables.get("documents"):
                    print(f"   ⚠️ No relevant tables found for question")
                    continue
                    
                context_tables = "\n".join(tables["documents"])
                print(f"   ✓ Retrieved {len(tables['documents'])} relevant tables")
                
            except Exception as e:
                print(f"   ❌ Error querying vector collection: {e}")
                continue
            
            # Step 3: Generate query using Azure OpenAI
            try:
                result = write_query_azure(
                    question=question,
                    client=client,
                    context_tables=context_tables
                )
                
                generated_query = result.get("query")
                print(f"   🤖 Generated query: {generated_query}")
                
                if generated_query == "Error generating query":
                    print(f"   ❌ Query generation failed")
                    continue
                    
                if not generated_query.strip().lower().startswith("select"):
                    print(f"   ⚠️ Generated query is not a SELECT statement")
                    continue
                    
            except Exception as e:
                print(f"   ❌ Error calling write_query_azure: {e}")
                continue
            
            # Step 4: Execute generated query and compare results
            try:
                cursor.execute(generated_query)
                generated_results = cursor.fetchall()
                print(f"   ✓ Generated query executed: {len(generated_results)} results")
                
                # Compare the results
                if self._compare_query_results(expected_results, generated_results):
                    print(f"   ✅ TEST PASSED: Results match!")
                    passed_tests += 1
                else:
                    print(f"   ❌ TEST FAILED: Results don't match")
                    print(f"      Expected: {expected_results[:2]}{'...' if len(expected_results) > 2 else ''}")
                    print(f"      Generated: {generated_results[:2]}{'...' if len(generated_results) > 2 else ''}")
                    
            except Exception as e:
                print(f"   ❌ Error executing generated query: {e}")
                
            print()  # Add spacing between tests
        
        # Final summary
        print(f"🎯 Test Summary: {passed_tests}/{total_tests} tests passed ({passed_tests/total_tests*100:.1f}%)")
        
        # Assert that at least 70% of tests pass (adjust threshold as needed)
        assert passed_tests >= total_tests * 0.7, f"Only {passed_tests}/{total_tests} tests passed. Expected at least 70%."
    
    def _compare_query_results(self, expected, generated):
        """Compare two result sets, handling different data types and ordering."""
        if len(expected) != len(generated):
            return False
        
        # For single-value results (like COUNT, AVG, SUM)
        if len(expected) == 1 and len(expected[0]) == 1:
            # Handle floating point comparison for averages
            if isinstance(expected[0][0], (int, float)) and isinstance(generated[0][0], (int, float)):
                return abs(float(expected[0][0]) - float(generated[0][0])) < 0.01
            else:
                return expected[0][0] == generated[0][0]
        
        # For multi-row results, compare as sets (ignoring order)
        try:
            expected_set = set(expected)
            generated_set = set(generated)
            return expected_set == generated_set
        except TypeError:
            # If results contain unhashable types, compare as sorted lists
            try:
                return sorted(expected) == sorted(generated)
            except TypeError:
                # If sorting fails, compare element by element (preserving order)
                return expected == generated
    
    def test_write_query_azure_error_handling(self):
        """Test error handling when no context tables are provided."""
        
        result = write_query_azure(
            question="Test question with no context",
            client=client,
            context_tables=""
        )
        
        # Should return error or handle gracefully
        assert "query" in result, "Result should contain 'query' key"
        print(f"✅ Error handling test: {result['query']}")
    
    def test_vector_database_integration(self):
        """Test that vector database returns relevant tables for questions."""
        
        test_questions = [
            "How many actors are there?",
            "What is the average rental rate?", 
            "How many customers do we have?"
        ]
        
        for question in test_questions:
            print(f"\n🔍 Testing vector DB for: {question}")
            
            try:
                tables = query_collection_azure(prompt=question)
                
                if tables and tables.get("documents"):
                    print(f"   ✓ Retrieved {len(tables['documents'])} tables")
                    # Check that we got actual table schemas
                    for doc in tables["documents"][:2]:  # Show first 2
                        print(f"   📋 Table info: {doc[:100]}...")
                else:
                    print(f"   ⚠️ No tables retrieved")
                    
            except Exception as e:
                print(f"   ❌ Error querying vector database: {e}")


if __name__ == "__main__":
    # Run tests with verbose output
    pytest.main([__file__, "-v", "-s"])